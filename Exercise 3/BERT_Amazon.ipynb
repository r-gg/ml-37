{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning with BERT as a base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:25:30.889496Z",
     "iopub.status.busy": "2023-02-21T16:25:30.889119Z",
     "iopub.status.idle": "2023-02-21T16:25:30.895179Z",
     "shell.execute_reply": "2023-02-21T16:25:30.893986Z",
     "shell.execute_reply.started": "2023-02-21T16:25:30.889465Z"
    },
    "id": "ApxsjLrFz5pa"
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForSequenceClassification # for sentimental analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Amazon Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:25:32.217448Z",
     "iopub.status.busy": "2023-02-21T16:25:32.217058Z",
     "iopub.status.idle": "2023-02-21T16:25:32.274706Z",
     "shell.execute_reply": "2023-02-21T16:25:32.273779Z",
     "shell.execute_reply.started": "2023-02-21T16:25:32.217414Z"
    },
    "id": "wvkCkBnL0Pxk"
   },
   "outputs": [],
   "source": [
    "amazon_reviews_df = pd.read_csv('data/cleaned_amazon_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "execution": {
     "iopub.execute_input": "2023-02-21T16:25:33.427002Z",
     "iopub.status.busy": "2023-02-21T16:25:33.426634Z",
     "iopub.status.idle": "2023-02-21T16:25:33.439152Z",
     "shell.execute_reply": "2023-02-21T16:25:33.437999Z",
     "shell.execute_reply.started": "2023-02-21T16:25:33.426970Z"
    },
    "id": "b9i9mqaQ0P9l",
    "outputId": "406aadfb-1ec4-4a7a-d4a0-b96d00882446"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>cleaned_review_length</th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>i wish would have gotten one earlier love it a...</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i ve learned this lesson again open the packag...</td>\n",
       "      <td>88</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>it is so slow and lags find better option</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>roller ball stopped working within months of m...</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i like the color and size but it few days out ...</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiments                                     cleaned_review  \\\n",
       "0   positive  i wish would have gotten one earlier love it a...   \n",
       "1    neutral  i ve learned this lesson again open the packag...   \n",
       "2    neutral          it is so slow and lags find better option   \n",
       "3    neutral  roller ball stopped working within months of m...   \n",
       "4    neutral  i like the color and size but it few days out ...   \n",
       "\n",
       "   cleaned_review_length  review_score  \n",
       "0                     19           5.0  \n",
       "1                     88           1.0  \n",
       "2                      9           2.0  \n",
       "3                     12           1.0  \n",
       "4                     21           1.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "execution": {
     "iopub.execute_input": "2023-02-21T16:25:36.318150Z",
     "iopub.status.busy": "2023-02-21T16:25:36.317789Z",
     "iopub.status.idle": "2023-02-21T16:25:36.339056Z",
     "shell.execute_reply": "2023-02-21T16:25:36.338107Z",
     "shell.execute_reply.started": "2023-02-21T16:25:36.318118Z"
    },
    "id": "xRDv28xIpc5b",
    "outputId": "61a19688-25c1-49d2-c4ea-de74be143d25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review_length</th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17340.000000</td>\n",
       "      <td>17340.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.300461</td>\n",
       "      <td>3.649077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>35.836540</td>\n",
       "      <td>1.673500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>571.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cleaned_review_length  review_score\n",
       "count           17340.000000  17340.000000\n",
       "mean               30.300461      3.649077\n",
       "std                35.836540      1.673500\n",
       "min                 0.000000      1.000000\n",
       "25%                 9.000000      2.000000\n",
       "50%                20.000000      5.000000\n",
       "75%                38.000000      5.000000\n",
       "max               571.000000      5.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:25:37.305719Z",
     "iopub.status.busy": "2023-02-21T16:25:37.305027Z",
     "iopub.status.idle": "2023-02-21T16:25:37.312290Z",
     "shell.execute_reply": "2023-02-21T16:25:37.311289Z",
     "shell.execute_reply.started": "2023-02-21T16:25:37.305676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17340, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:25:38.062353Z",
     "iopub.status.busy": "2023-02-21T16:25:38.061262Z",
     "iopub.status.idle": "2023-02-21T16:25:38.074724Z",
     "shell.execute_reply": "2023-02-21T16:25:38.072367Z",
     "shell.execute_reply.started": "2023-02-21T16:25:38.062288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments               0\n",
       "cleaned_review           3\n",
       "cleaned_review_length    0\n",
       "review_score             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> It has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:25:40.502003Z",
     "iopub.status.busy": "2023-02-21T16:25:40.501625Z",
     "iopub.status.idle": "2023-02-21T16:25:40.691144Z",
     "shell.execute_reply": "2023-02-21T16:25:40.690247Z",
     "shell.execute_reply.started": "2023-02-21T16:25:40.501970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "amazon_reviews_df.sentiments.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:25:42.753496Z",
     "iopub.status.busy": "2023-02-21T16:25:42.752337Z",
     "iopub.status.idle": "2023-02-21T16:25:42.759987Z",
     "shell.execute_reply": "2023-02-21T16:25:42.758814Z",
     "shell.execute_reply.started": "2023-02-21T16:25:42.753449Z"
    },
    "id": "lUN-3ThJ0QEt"
   },
   "outputs": [],
   "source": [
    "# remove not needed columns\n",
    "amazon_reviews_df.drop(columns=[\"cleaned_review_length\", \"review_score\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:25:43.982569Z",
     "iopub.status.busy": "2023-02-21T16:25:43.981392Z",
     "iopub.status.idle": "2023-02-21T16:25:43.993877Z",
     "shell.execute_reply": "2023-02-21T16:25:43.992796Z",
     "shell.execute_reply.started": "2023-02-21T16:25:43.982518Z"
    },
    "id": "hIBZAt7V0QM0"
   },
   "outputs": [],
   "source": [
    "# remove NaN values\n",
    "amazon_reviews_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:25:46.191602Z",
     "iopub.status.busy": "2023-02-21T16:25:46.189618Z",
     "iopub.status.idle": "2023-02-21T16:25:46.202762Z",
     "shell.execute_reply": "2023-02-21T16:25:46.201776Z",
     "shell.execute_reply.started": "2023-02-21T16:25:46.191556Z"
    },
    "id": "GoBlrTDG0bEM"
   },
   "outputs": [],
   "source": [
    "X_amazon_reviews = amazon_reviews_df.drop(columns=['sentiments'])\n",
    "y_amazon_reviews = amazon_reviews_df['sentiments']\n",
    "\n",
    "# encode target class\n",
    "le = LabelEncoder()\n",
    "y_amazon_reviews_labels = le.fit_transform(y_amazon_reviews)\n",
    "# apply one-hot-encoding\n",
    "y_amazon_reviews = to_categorical(y_amazon_reviews_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:25:46.955009Z",
     "iopub.status.busy": "2023-02-21T16:25:46.954333Z",
     "iopub.status.idle": "2023-02-21T16:25:46.964882Z",
     "shell.execute_reply": "2023-02-21T16:25:46.963902Z",
     "shell.execute_reply.started": "2023-02-21T16:25:46.954973Z"
    },
    "id": "-dLtxS800bQj"
   },
   "outputs": [],
   "source": [
    "# split train-test 80-20\n",
    "X_train_reviews, X_test_reviews, y_train_reviews, y_test_reviews = train_test_split(X_amazon_reviews,\n",
    "                                                                                    y_amazon_reviews,\n",
    "                                                                                    random_state=42,\n",
    "                                                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:25:47.851535Z",
     "iopub.status.busy": "2023-02-21T16:25:47.850780Z",
     "iopub.status.idle": "2023-02-21T16:25:47.860776Z",
     "shell.execute_reply": "2023-02-21T16:25:47.859814Z",
     "shell.execute_reply.started": "2023-02-21T16:25:47.851502Z"
    },
    "id": "wIbcg8Uy0bYh"
   },
   "outputs": [],
   "source": [
    "# split train-validation 80-20\n",
    "X_train_reviews, X_valid_reviews, y_train_reviews, y_valid_reviews = train_test_split(X_train_reviews,\n",
    "                                                                                      y_train_reviews,\n",
    "                                                                                      random_state=42,\n",
    "                                                                                      test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation for BERT model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:25:52.538788Z",
     "iopub.status.busy": "2023-02-21T16:25:52.538423Z",
     "iopub.status.idle": "2023-02-21T16:25:55.557240Z",
     "shell.execute_reply": "2023-02-21T16:25:55.556282Z",
     "shell.execute_reply.started": "2023-02-21T16:25:52.538758Z"
    },
    "id": "b4cAi5PZqOEE"
   },
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:25:55.559714Z",
     "iopub.status.busy": "2023-02-21T16:25:55.559363Z",
     "iopub.status.idle": "2023-02-21T16:25:59.667271Z",
     "shell.execute_reply": "2023-02-21T16:25:59.666275Z",
     "shell.execute_reply.started": "2023-02-21T16:25:55.559679Z"
    },
    "id": "BuNnXPwB0iNR"
   },
   "outputs": [],
   "source": [
    "# apply tokenizer or our dataset\n",
    "train_encodings = tokenizer(list(X_train_reviews['cleaned_review']),\n",
    "                            truncation=True,\n",
    "                            padding=\"max_length\",\n",
    "                            return_tensors=\"np\",\n",
    "                            return_token_type_ids=False)\n",
    "valid_encodings = tokenizer(list(X_valid_reviews['cleaned_review']),\n",
    "                            truncation=True,\n",
    "                            padding=\"max_length\",\n",
    "                            return_tensors=\"np\",\n",
    "                            return_token_type_ids=False)\n",
    "test_encodings = tokenizer(list(X_test_reviews['cleaned_review']),\n",
    "                           truncation=True,\n",
    "                           padding=\"max_length\",\n",
    "                           return_tensors=\"np\",\n",
    "                           return_token_type_ids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:25:59.669279Z",
     "iopub.status.busy": "2023-02-21T16:25:59.668922Z",
     "iopub.status.idle": "2023-02-21T16:25:59.899604Z",
     "shell.execute_reply": "2023-02-21T16:25:59.898649Z",
     "shell.execute_reply.started": "2023-02-21T16:25:59.669241Z"
    },
    "id": "brQmTj770iSc"
   },
   "outputs": [],
   "source": [
    "# prepare tensor dataset that can be used for model training\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    y_train_reviews\n",
    "))\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(valid_encodings),\n",
    "    y_valid_reviews\n",
    "))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    y_test_reviews\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:26:03.990291Z",
     "iopub.status.busy": "2023-02-21T16:26:03.989912Z",
     "iopub.status.idle": "2023-02-21T16:26:04.001269Z",
     "shell.execute_reply": "2023-02-21T16:26:03.999998Z",
     "shell.execute_reply.started": "2023-02-21T16:26:03.990258Z"
    },
    "id": "Pdvm9PEX0iV6"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_dataset = train_dataset.shuffle(1000).batch(batch_size, drop_remainder=True)\n",
    "valid_dataset = valid_dataset.shuffle(1000).batch(batch_size, drop_remainder=True)\n",
    "test_dataset = test_dataset.shuffle(1000).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:26:04.876031Z",
     "iopub.status.busy": "2023-02-21T16:26:04.875685Z",
     "iopub.status.idle": "2023-02-21T16:26:04.881587Z",
     "shell.execute_reply": "2023-02-21T16:26:04.880289Z",
     "shell.execute_reply.started": "2023-02-21T16:26:04.876002Z"
    },
    "id": "TyjXFFetg5kB"
   },
   "outputs": [],
   "source": [
    "seq_num = train_dataset.take(1).element_spec[0]['input_ids'].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamater Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T23:15:18.746229Z",
     "iopub.status.busy": "2023-02-20T23:15:18.745807Z",
     "iopub.status.idle": "2023-02-21T01:49:51.875124Z",
     "shell.execute_reply": "2023-02-21T01:49:51.873887Z",
     "shell.execute_reply.started": "2023-02-20T23:15:18.746194Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  2e-05\n",
      "activation:  sigmoid\n",
      "epsilon:  1e-08\n",
      "Epoch 1/3\n",
      "1161/1161 [==============================] - 755s 643ms/step - loss: 0.4425 - accuracy: 0.8168 - val_loss: 0.3012 - val_accuracy: 0.8811\n",
      "Epoch 2/3\n",
      "1161/1161 [==============================] - 744s 641ms/step - loss: 0.2125 - accuracy: 0.9166 - val_loss: 0.2675 - val_accuracy: 0.9049\n",
      "Epoch 3/3\n",
      "1161/1161 [==============================] - 744s 641ms/step - loss: 0.1130 - accuracy: 0.9588 - val_loss: 0.3058 - val_accuracy: 0.8964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  3e-05\n",
      "activation:  sigmoid\n",
      "epsilon:  1e-08\n",
      "Epoch 1/3\n",
      "1161/1161 [==============================] - 755s 642ms/step - loss: 0.4213 - accuracy: 0.8205 - val_loss: 0.2894 - val_accuracy: 0.8789\n",
      "Epoch 2/3\n",
      "1161/1161 [==============================] - 743s 640ms/step - loss: 0.2122 - accuracy: 0.9123 - val_loss: 0.2521 - val_accuracy: 0.8999\n",
      "Epoch 3/3\n",
      "1161/1161 [==============================] - 743s 640ms/step - loss: 0.1166 - accuracy: 0.9537 - val_loss: 0.3015 - val_accuracy: 0.8907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  2e-05\n",
      "activation:  sigmoid\n",
      "epsilon:  1e-07\n",
      "Epoch 1/3\n",
      "1161/1161 [==============================] - 755s 642ms/step - loss: 0.4408 - accuracy: 0.8129 - val_loss: 0.2846 - val_accuracy: 0.8853\n",
      "Epoch 2/3\n",
      "1161/1161 [==============================] - 744s 641ms/step - loss: 0.2015 - accuracy: 0.9213 - val_loss: 0.2824 - val_accuracy: 0.9025\n",
      "Epoch 3/3\n",
      "1161/1161 [==============================] - 744s 640ms/step - loss: 0.1029 - accuracy: 0.9619 - val_loss: 0.3314 - val_accuracy: 0.9032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  3e-05\n",
      "activation:  sigmoid\n",
      "epsilon:  1e-07\n",
      "Epoch 1/3\n",
      "1161/1161 [==============================] - 755s 642ms/step - loss: 0.4331 - accuracy: 0.8169 - val_loss: 0.3095 - val_accuracy: 0.8750\n",
      "Epoch 2/3\n",
      "1161/1161 [==============================] - 744s 641ms/step - loss: 0.2064 - accuracy: 0.9184 - val_loss: 0.3044 - val_accuracy: 0.8949\n",
      "Epoch 3/3\n",
      "1161/1161 [==============================] - 744s 641ms/step - loss: 0.1235 - accuracy: 0.9521 - val_loss: 0.2867 - val_accuracy: 0.9019\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.00002, 0.00003]\n",
    "input_activation = ['sigmoid']\n",
    "epsilon = [1e-08, 1e-07]\n",
    "\n",
    "for act in input_activation:\n",
    "    for eps in epsilon:\n",
    "        for lr in learning_rates:\n",
    "            model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "            input_ids = tf.keras.layers.Input(shape=(seq_num,), name='input_ids', dtype='int32')\n",
    "            attention_mask = tf.keras.layers.Input(shape=(seq_num,), name='attention_mask', dtype='int32')\n",
    "\n",
    "            embeddings = model.bert(input_ids, attention_mask)[1]\n",
    "\n",
    "            x = tf.keras.layers.Dense(seq_num * 2, activation=act)(embeddings)\n",
    "            y = tf.keras.layers.Dense(len(y_amazon_reviews[0]), activation='softmax', name='outputs')(x)\n",
    "\n",
    "            model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=y)\n",
    "\n",
    "            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr, epsilon=eps), \n",
    "                          loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                          metrics=[tf.keras.metrics.CategoricalAccuracy('accuracy')])\n",
    "            print(\"lr: \", lr)\n",
    "            print(\"activation: \", act)\n",
    "            print(\"epsilon: \", eps)\n",
    "            model.fit(train_dataset, validation_data=valid_dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr:  1e-05\n",
    "\n",
    "activation:  sigmoid\n",
    "\n",
    "epsilon:  1e-08\n",
    "\n",
    "Epoch 1/3\n",
    "1161/1161 [==============================] - 754s 642ms/step - loss: 0.4631 - accuracy: 0.8053 - val_loss: 0.3493 - val_accuracy: 0.8422\n",
    "\n",
    "Epoch 2/3\n",
    "1161/1161 [==============================] - 744s 641ms/step - loss: 0.2282 - accuracy: 0.9081 - val_loss: 0.2723 - val_accuracy: 0.8881\n",
    "\n",
    "Epoch 3/3\n",
    "1161/1161 [==============================] - 744s 641ms/step - loss: 0.1226 - accuracy: 0.9543 - val_loss: 0.2892 - val_accuracy: 0.8984"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-20T21:53:54.785287Z",
     "iopub.status.idle": "2023-02-20T21:53:54.786222Z",
     "shell.execute_reply": "2023-02-20T21:53:54.785957Z",
     "shell.execute_reply.started": "2023-02-20T21:53:54.785930Z"
    }
   },
   "source": [
    "lr:  1e-05\n",
    "\n",
    "activation:  sigmoid\n",
    "\n",
    "epsilon:  1e-07\n",
    "\n",
    "Epoch 1/3\n",
    "1161/1161 [==============================] - 797s 678ms/step - loss: 0.4817 - accuracy: 0.8000 - val_loss: 0.3282 - val_accuracy: 0.8610\n",
    "\n",
    "Epoch 2/3\n",
    "1161/1161 [==============================] - 785s 676ms/step - loss: 0.2470 - accuracy: 0.9014 - val_loss: 0.3651 - val_accuracy: 0.8542\n",
    "\n",
    "Epoch 3/3\n",
    "1161/1161 [==============================] - 744s 641ms/step - loss: 0.1358 - accuracy: 0.9488 - val_loss: 0.3326 - val_accuracy: 0.8925"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr:  0.0001\n",
    "\n",
    "activation:  sigmoid\n",
    "\n",
    "epsilon:  1e-07\n",
    "\n",
    "Epoch 1/3\n",
    "1161/1161 [==============================] - 755s 642ms/step - loss: 0.7267 - accuracy: 0.7011 - val_loss: 0.8825 - val_accuracy: 0.5870\n",
    "\n",
    "Epoch 2/3\n",
    "1161/1161 [==============================] - 744s 641ms/step - loss: 0.9163 - accuracy: 0.5415 - val_loss: 0.9208 - val_accuracy: 0.5553\n",
    "\n",
    "Epoch 3/3\n",
    "1161/1161 [==============================] - 744s 641ms/step - loss: 0.9286 - accuracy: 0.5250 - val_loss: 0.9214 - val_accuracy: 0.5555"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr:  2e-05\n",
    "activation:  sigmoid\n",
    "epsilon:  1e-08\n",
    "Epoch 1/3\n",
    "1161/1161 [==============================] - 755s 643ms/step - loss: 0.4425 - accuracy: 0.8168 - val_loss: 0.3012 - val_accuracy: 0.8811\n",
    "\n",
    "Epoch 2/3\n",
    "1161/1161 [==============================] - 744s 641ms/step - loss: 0.2125 - accuracy: 0.9166 - val_loss: 0.2675 - val_accuracy: 0.9049\n",
    "\n",
    "Epoch 3/3\n",
    "1161/1161 [==============================] - 744s 641ms/step - loss: 0.1130 - accuracy: 0.9588 - val_loss: 0.3058 - val_accuracy: 0.8964\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr:  3e-05\n",
    "    \n",
    "activation:  sigmoid\n",
    "    \n",
    "epsilon:  1e-08\n",
    "\n",
    "Epoch 1/3\n",
    "1161/1161 [==============================] - 755s 642ms/step - loss: 0.4213 - accuracy: 0.8205 - val_loss: 0.2894 - val_accuracy: 0.8789\n",
    "\n",
    "Epoch 2/3\n",
    "1161/1161 [==============================] - 743s 640ms/step - loss: 0.2122 - accuracy: 0.9123 - val_loss: 0.2521 - val_accuracy: 0.8999\n",
    "\n",
    "Epoch 3/3\n",
    "1161/1161 [==============================] - 743s 640ms/step - loss: 0.1166 - accuracy: 0.9537 - val_loss: 0.3015 - val_accuracy: 0.8907"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr:  2e-05\n",
    "\n",
    "activation:  sigmoid\n",
    "\n",
    "epsilon:  1e-07\n",
    "\n",
    "Epoch 1/3\n",
    "1161/1161 [==============================] - 755s 642ms/step - loss: 0.4408 - accuracy: 0.8129 - val_loss: 0.2846 - val_accuracy: 0.8853\n",
    "\n",
    "Epoch 2/3\n",
    "1161/1161 [==============================] - 744s 641ms/step - loss: 0.2015 - accuracy: 0.9213 - val_loss: 0.2824 - val_accuracy: 0.9025\n",
    "\n",
    "Epoch 3/3\n",
    "1161/1161 [==============================] - 744s 640ms/step - loss: 0.1029 - accuracy: 0.9619 - val_loss: 0.3314 - val_accuracy: 0.9032"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr:  3e-05\n",
    "\n",
    "activation:  sigmoid\n",
    "\n",
    "epsilon:  1e-07\n",
    "\n",
    "Epoch 1/3\n",
    "1161/1161 [==============================] - 755s 642ms/step - loss: 0.4331 - accuracy: 0.8169 - val_loss: 0.3095 - val_accuracy: 0.8750\n",
    "\n",
    "Epoch 2/3\n",
    "1161/1161 [==============================] - 744s 641ms/step - loss: 0.2064 - accuracy: 0.9184 - val_loss: 0.3044 - val_accuracy: 0.8949\n",
    "\n",
    "Epoch 3/3\n",
    "1161/1161 [==============================] - 744s 641ms/step - loss: 0.1235 - accuracy: 0.9521 - val_loss: 0.2867 - val_accuracy: 0.9019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development using best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:26:11.032884Z",
     "iopub.status.busy": "2023-02-21T16:26:11.032192Z",
     "iopub.status.idle": "2023-02-21T16:26:12.943908Z",
     "shell.execute_reply": "2023-02-21T16:26:12.942975Z",
     "shell.execute_reply.started": "2023-02-21T16:26:11.032846Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:26:12.946379Z",
     "iopub.status.busy": "2023-02-21T16:26:12.945978Z",
     "iopub.status.idle": "2023-02-21T16:26:14.629216Z",
     "shell.execute_reply": "2023-02-21T16:26:14.628240Z",
     "shell.execute_reply.started": "2023-02-21T16:26:12.946339Z"
    },
    "id": "vgYxtcfd0pKe"
   },
   "outputs": [],
   "source": [
    "# embedd input and output layers for model\n",
    "input_ids = tf.keras.layers.Input(shape=(seq_num,), name='input_ids', dtype='int32')\n",
    "attention_mask = tf.keras.layers.Input(shape=(seq_num,), name='attention_mask', dtype='int32')\n",
    "\n",
    "embeddings = model.bert(input_ids, attention_mask)[1]\n",
    "\n",
    "x = tf.keras.layers.Dense(seq_num * 2, activation='relu')(embeddings)\n",
    "y = tf.keras.layers.Dense(len(y_amazon_reviews[0]), activation='softmax', name='outputs')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-21T16:26:15.173871Z",
     "iopub.status.busy": "2023-02-21T16:26:15.173180Z",
     "iopub.status.idle": "2023-02-21T16:26:15.233532Z",
     "shell.execute_reply": "2023-02-21T16:26:15.232719Z",
     "shell.execute_reply.started": "2023-02-21T16:26:15.173824Z"
    },
    "id": "LfVUSAcf0pOm",
    "outputId": "65a4cf8e-e6ef-4e79-a0dc-aeb5946ab3e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 512,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1024)         787456      ['bert[0][1]']                   \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 3)            3075        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 110,272,771\n",
      "Trainable params: 110,272,771\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build new model structure\n",
    "model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=y)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T16:26:16.066223Z",
     "iopub.status.busy": "2023-02-21T16:26:16.065861Z",
     "iopub.status.idle": "2023-02-21T16:26:16.085169Z",
     "shell.execute_reply": "2023-02-21T16:26:16.084289Z",
     "shell.execute_reply.started": "2023-02-21T16:26:16.066191Z"
    },
    "id": "2EOAH4ap0pSO"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-05, epsilon=1e-07), \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy('accuracy')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model (requires a lot of time) - Can be skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-21T16:26:20.259069Z",
     "iopub.status.busy": "2023-02-21T16:26:20.258693Z",
     "iopub.status.idle": "2023-02-21T17:07:45.128508Z",
     "shell.execute_reply": "2023-02-21T17:07:45.127603Z",
     "shell.execute_reply.started": "2023-02-21T16:26:20.259037Z"
    },
    "id": "wQxd_Os_0sJV",
    "outputId": "d952a348-3aca-4023-aafa-53b01d4ba25e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1386/1386 [==============================] - 836s 596ms/step - loss: 0.4189 - accuracy: 0.8200 - val_loss: 0.2828 - val_accuracy: 0.8848\n",
      "Epoch 2/3\n",
      "1386/1386 [==============================] - 824s 595ms/step - loss: 0.1973 - accuracy: 0.9237 - val_loss: 0.2894 - val_accuracy: 0.8970\n",
      "Epoch 3/3\n",
      "1386/1386 [==============================] - 824s 595ms/step - loss: 0.1088 - accuracy: 0.9616 - val_loss: 0.2508 - val_accuracy: 0.9118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f76f0bb5fd0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=valid_dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-21T17:08:13.142061Z",
     "iopub.status.busy": "2023-02-21T17:08:13.141698Z",
     "iopub.status.idle": "2023-02-21T17:08:42.984527Z",
     "shell.execute_reply": "2023-02-21T17:08:42.983483Z",
     "shell.execute_reply.started": "2023-02-21T17:08:13.142029Z"
    },
    "id": "yPUIRZMx0sNn",
    "outputId": "60979897-c138-4dd0-9784-236522132cf8"
   },
   "outputs": [],
   "source": [
    "# save model to be able to load later\n",
    "model.save('bert-amazon-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load saved model to skip training\n",
    "Model can be downloaded from https://drive.google.com/drive/folders/1MiA1fvj2YS6USLhtnXFTJDFWaTA7dNtN?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = tf.keras.models.load_model('models/bert-amazon-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = saved_model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fZolENkkqYi",
    "outputId": "8ad925e8-ce21-4228-f231-48011aacecc7"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-21T17:08:50.240977Z",
     "iopub.status.busy": "2023-02-21T17:08:50.240605Z",
     "iopub.status.idle": "2023-02-21T17:10:12.181257Z",
     "shell.execute_reply": "2023-02-21T17:10:12.180215Z",
     "shell.execute_reply.started": "2023-02-21T17:08:50.240946Z"
    },
    "id": "XOt2mvmnNidQ",
    "outputId": "de7284af-3398-40c4-c319-31bf4dc4c57c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433/433 [==============================] - 77s 178ms/step - loss: 0.2613 - accuracy: 0.9189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26130756735801697, 0.9188799262046814]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create result dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 31s 31s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n"
     ]
    }
   ],
   "source": [
    "test_res = []\n",
    "pred_res = []\n",
    "iterator = test_dataset.as_numpy_iterator()\n",
    "while True:\n",
    "    batch = None\n",
    "    try:\n",
    "        batch = iterator.next()\n",
    "    except:\n",
    "        break\n",
    "    train_batch = batch[0]\n",
    "    test_batch = batch[1]\n",
    "    pred_batch = saved_model.predict(train_batch)\n",
    "    size = len(test_batch)\n",
    "    for i in range(size):\n",
    "        pred_res.append(np.argmax(pred_batch[i], axis=0))\n",
    "        test_res.append(np.argmax(test_batch[i], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_results = classification_report(test_res, pred_res, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame.from_dict(reviews_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['train_time'] = 826 + 824 + 824\n",
    "df_results['test_time'] = 77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "      <th>train_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.892562</td>\n",
       "      <td>0.880094</td>\n",
       "      <td>0.947585</td>\n",
       "      <td>0.91888</td>\n",
       "      <td>0.906747</td>\n",
       "      <td>0.918285</td>\n",
       "      <td>2474</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.900561</td>\n",
       "      <td>0.969506</td>\n",
       "      <td>0.91888</td>\n",
       "      <td>0.851927</td>\n",
       "      <td>0.918880</td>\n",
       "      <td>2474</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.775583</td>\n",
       "      <td>0.890210</td>\n",
       "      <td>0.958420</td>\n",
       "      <td>0.91888</td>\n",
       "      <td>0.874738</td>\n",
       "      <td>0.917239</td>\n",
       "      <td>2474</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>315.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>1902.000000</td>\n",
       "      <td>0.91888</td>\n",
       "      <td>3464.000000</td>\n",
       "      <td>3464.000000</td>\n",
       "      <td>2474</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0            1            2  accuracy    macro avg  \\\n",
       "precision    0.892562     0.880094     0.947585   0.91888     0.906747   \n",
       "recall       0.685714     0.900561     0.969506   0.91888     0.851927   \n",
       "f1-score     0.775583     0.890210     0.958420   0.91888     0.874738   \n",
       "support    315.000000  1247.000000  1902.000000   0.91888  3464.000000   \n",
       "\n",
       "           weighted avg  train_time  test_time  \n",
       "precision      0.918285        2474         77  \n",
       "recall         0.918880        2474         77  \n",
       "f1-score       0.917239        2474         77  \n",
       "support     3464.000000        2474         77  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('results/bert/reviews_results.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
